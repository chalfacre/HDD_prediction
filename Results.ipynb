{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Results\n",
    "Run XGBoost and Random Forrest Regressor using cleaned data file containing only the following model: ST4000DM000\n",
    "\n",
    "Conclusion: SMART data alone is not a \"good enough\" predictor for hard drive failure.\n",
    "The test set used below contained data for over 11,000 hard drives.\n",
    "\n",
    "SMART attributes used in this set: 5,187,188,197,198 (previous runs were completed with all SMART attributes, this one yields the best results)\n",
    "\n",
    "The false negative rate was high due to those failed hard drives not having any relevant SMART data indicators for failure (i.e. SMART counters were 0's, yet drive failed -- 26% of failed drives fit that criteria)\n",
    "\n",
    "### Example results:\n",
    "#### Total number of drives 11569\n",
    "#### Number of failed drives 42\n",
    "#### Number of predicted failures 25\n",
    "#### Number of false positives 9\n",
    "#### Number of false negatives 26\n",
    "#### Number of true negatives 0.0\n",
    "#### Number of true positives 16.0\n",
    "#### Fmeasure = 0.733944954128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    11527\n",
      "1       42\n",
      "Name: failure, dtype: int64\n",
      "0    23399\n",
      "1       89\n",
      "Name: failure, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy import loadtxt\n",
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import ensemble, metrics \n",
    "\n",
    "# load data\n",
    "hdd = pd.read_csv('../input/ST4000DM000_clean_SMART_harddrive.csv')\n",
    "\n",
    "hdd_group = hdd.groupby('serial_number')\n",
    "hdd_last_day = hdd_group.nth(-1) # take the last row from each group\n",
    "\n",
    "# the number of drives in the dataset\n",
    "uniq_serial_num = pd.Series(hdd_last_day.index.unique())\n",
    "uniq_serial_num.shape\n",
    "\n",
    "# hold out 33% of data for testing\n",
    "test_ids = uniq_serial_num.sample(frac=0.33)\n",
    "\n",
    "train = hdd_last_day.query('index not in @test_ids')\n",
    "test = hdd_last_day.query('index in @test_ids')\n",
    "\n",
    "print test['failure'].value_counts()\n",
    "print train['failure'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               failure  r187           r188  r197  r198  r5  sum\n",
      "serial_number                                                   \n",
      "0                    0     0   0.000000e+00     0     0   0    0\n",
      "2                    0     0  1.482197e-323     0     0   0    0\n",
      "4                    0     0   0.000000e+00     0     0   0    0\n",
      "5                    0     0   0.000000e+00     0     0   0    0\n",
      "6                    0    30   0.000000e+00     0     0   0   30\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create prediction dataframe\n",
    "# serial_number,r5,r187,r188,r197,r198,fail,predxgb,altpred  - INTs\n",
    "predict_df = pd.DataFrame({'failure': test['failure'], 'r5':test['smart_5_raw'], 'r187':test['smart_187_raw'], \\\n",
    "    'r188':test['smart_188_raw'], 'r197':test['smart_197_raw'], 'r198':test['smart_198_raw']})\n",
    "predict_df['sum'] = (predict_df['r5'] + predict_df['r187'] + predict_df['r188'].astype(float).round() + \\\n",
    "    predict_df['r197'] + predict_df['r198']).astype(float).round()\n",
    "\n",
    "print predict_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB - Accuracy: 99.70%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_labels = train['failure']\n",
    "test_labels = test['failure']\n",
    "train = train.drop('failure', axis=1)\n",
    "test = test.drop('failure', axis=1)\n",
    "\n",
    "X_train = train\n",
    "y_train = train_labels\n",
    "X_test = test\n",
    "y_test = test_labels\n",
    "\n",
    "# model\n",
    "\n",
    "model = XGBClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# make predictions for test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"XGB - Accuracy: %.2f%%\" % (accuracy * 100.0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 11544, 1: 25}\n"
     ]
    }
   ],
   "source": [
    "unique, counts = np.unique(y_pred, return_counts=True)\n",
    "print dict(zip(unique, counts))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               failure  sum  xgb  fp  fn  tp  tn\n",
      "serial_number                                   \n",
      "0                    0    0    0   0   0   0   0\n",
      "2                    0    0    0   0   0   0   0\n",
      "4                    0    0    0   0   0   0   0\n",
      "5                    0    0    0   0   0   0   0\n",
      "6                    0    1    0   0   0   0   0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "predict_df['xgb'] = y_pred\n",
    "columns_to_drop = ['r5', 'r187', 'r188', 'r197', 'r198']\n",
    "predict_df = predict_df.drop(columns_to_drop, axis=1)\n",
    "\n",
    "\n",
    "predict_df['sum'] = predict_df['sum'].map(lambda x: 1 if x > 0 else 0)\n",
    "#predict_df.to_csv(\"ST4000DM000_pred.csv\", index='false')\n",
    "predict_df['fp'] = (predict_df['xgb'] - predict_df['failure'])\n",
    "predict_df['fp'] = predict_df['fp'].map(lambda x: 1 if x > 0 else 0)\n",
    "predict_df['fn'] = predict_df['failure'] - predict_df['xgb']\n",
    "predict_df['fn'] = predict_df['fn'].map(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "predict_df.loc[(predict_df['failure'] == 1) & (predict_df['xgb'] == 1), 'tp'] = 1\n",
    "predict_df.loc[(predict_df['failure'] == 0) & (predict_df['xgb'] == 0), 'tn'] = 0\n",
    "predict_df.fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "print predict_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of total drives 11569\n",
      "Number of failed drives 42\n",
      "Number of predicted failures 25\n",
      "Number of false positives 9\n",
      "Number of false negatives 26\n",
      "Number of true negatives 0.0\n",
      "Number of true positives 16.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print (\"Number of total drives {}\".format(predict_df.shape[0]))\n",
    "print (\"Number of failed drives {}\".format(predict_df['failure'].sum())) #value_counts().shape[0]))\n",
    "print (\"Number of predicted failures {}\".format(predict_df['xgb'].sum())) #value_counts().shape[0]))\n",
    "print (\"Number of false positives {}\".format(predict_df['fp'].sum()))\n",
    "print (\"Number of false negatives {}\".format(predict_df['fn'].sum()))\n",
    "print (\"Number of true negatives {}\".format(predict_df['tn'].sum()))\n",
    "print (\"Number of true positives {}\".format(predict_df['tp'].sum()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " FPrate = 1.0\n",
      " Fmeasure = 0.733944954128\n",
      "Number of code predicted failures 144\n"
     ]
    }
   ],
   "source": [
    "fp = predict_df['fp'].sum()\n",
    "fn = predict_df['fn'].sum()\n",
    "tn = predict_df['tn'].sum()\n",
    "tp = predict_df['tp'].sum()\n",
    "recall = tp / (tp + fn)\n",
    "FPrate = fp / (fp + tn)\n",
    "precision = tp / tp + fp\n",
    "Fmeasure = (2 * precision * recall) / (precision + recall)\n",
    "print (\" FPrate = {}\".format(FPrate))\n",
    "print (\" Fmeasure = {}\".format(Fmeasure))\n",
    "print (\"Number of code predicted failures {}\".format(predict_df['sum'].sum()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('logloss', 0.10747714984818632)\n",
      "('roc_auc', 0.67818104078622865)\n"
     ]
    }
   ],
   "source": [
    "predict_df.to_csv(\"ST4000DM000_pred_all_parms.csv\", index='false')\n",
    "columns_to_drop = ['fp', 'fn', 'sum', 'tp', 'tn']\n",
    "predict_df = predict_df.drop(columns_to_drop, axis=1)\n",
    "rf = ensemble.RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "preds_rf = rf.predict(X_test)\n",
    "\n",
    "predict_df['RF'] = preds_rf\n",
    "print('logloss', metrics.log_loss(y_true=y_test, y_pred=preds_rf))\n",
    "print('roc_auc', metrics.roc_auc_score(y_true=y_test, y_score=preds_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               failure  xgb  RF\n",
      "serial_number                  \n",
      "0                    0    0   0\n",
      "2                    0    0   0\n",
      "4                    0    0   0\n",
      "5                    0    0   0\n",
      "6                    0    0   0\n"
     ]
    }
   ],
   "source": [
    "# create file to see predicted vs actual\n",
    "predict_df.to_csv(\"ST4000DM000_pred_limited.csv\", index='false')\n",
    "print predict_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
